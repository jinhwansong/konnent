'use client';

import { useCallback, useEffect, useRef, useState } from 'react';
import SimplePeer, { SignalData } from 'simple-peer';
import { Socket } from 'socket.io-client';

interface UseWebRTCOptions {
  roomId: string;
  userId: string;
  socket: Socket | null; // ì†Œì¼“ì€ ì´ˆê¸°ì—ëŠ” nullì¼ ìˆ˜ ìˆìŒ
}

interface WebRTCUser {
  id: string;
  name: string;
  image?: string;
  isMentor: boolean;
  stream?: MediaStream;
}

interface WebRTCSignalPayload {
  roomId: string;
  userId: string;
  targetUserId: string;
  signal: SignalData;
  type: 'offer' | 'answer' | 'ice_candidate';
}

// í™”ë©´ ê³µìœ  ì œì•½ ì¡°ê±´ íƒ€ì… (DOM lib ì¼ë¶€ í™˜ê²½ í˜¸í™˜)
type DisplaySurfaceType =
  | 'browser'
  | 'window'
  | 'application'
  | 'monitor'
  | 'screen'
  | 'tab';
type DisplayMediaConstraints = {
  video:
    | boolean
    | (MediaTrackConstraints & { displaySurface?: DisplaySurfaceType });
  audio?: boolean | MediaTrackConstraints;
};

interface RemoteTrackState {
  isAudioEnabled: boolean;
  isVideoEnabled: boolean;
}

export const useWebRTC = ({ roomId, userId, socket }: UseWebRTCOptions) => {
  const [localStream, setLocalStream] = useState<MediaStream | null>(null);
  const [remoteStreams, setRemoteStreams] = useState<Map<string, MediaStream>>(
    new Map()
  );
  const [remoteTrackStates, setRemoteTrackStates] = useState<
    Map<string, RemoteTrackState>
  >(new Map());
  const [isConnected, setIsConnected] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [isScreenSharing, setIsScreenSharing] = useState(false);
  const [originalStream, setOriginalStream] = useState<MediaStream | null>(
    null
  );

  type PeerInstance = SimplePeer.Instance;
  const peersRef = useRef<Map<string, PeerInstance>>(new Map());
  const localVideoRef = useRef<HTMLVideoElement>(null);

  // ë¡œì»¬ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”
  const initializeLocalStream = useCallback(async (audioDeviceId?: string) => {
    try {
      setIsLoading(true);
      setError(null);

      console.log(
        'ğŸ¥ Initializing local stream...',
        audioDeviceId ? `with device: ${audioDeviceId}` : 'default device'
      );

      const audioConstraints = audioDeviceId
        ? {
            deviceId: { exact: audioDeviceId },
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
          }
        : {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
          };

      let stream: MediaStream | null = null;

      // ë¨¼ì € ë¹„ë””ì˜¤ + ì˜¤ë””ì˜¤ ì‹œë„
      try {
        stream = await navigator.mediaDevices.getUserMedia({
          video: {
            width: { ideal: 1280 },
            height: { ideal: 720 },
          },
          audio: audioConstraints,
        });
        console.log('âœ… Video + Audio stream initialized');
      } catch (videoError) {
        console.warn('âš ï¸ Video failed, trying audio only:', videoError);

        // ë¹„ë””ì˜¤ ì‹¤íŒ¨ ì‹œ ì˜¤ë””ì˜¤ë§Œ ì‹œë„
        try {
          stream = await navigator.mediaDevices.getUserMedia({
            audio: audioConstraints,
          });
          console.log('âœ… Audio-only stream initialized');
          setError('ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë””ì˜¤ë§Œìœ¼ë¡œ ì—°ê²°í•©ë‹ˆë‹¤.');
        } catch (audioError) {
          console.error('âŒ Audio also failed:', audioError);
          throw audioError;
        }
      }

      if (stream) {
        console.log('Stream tracks:', {
          video: stream.getVideoTracks().length,
          audio: stream.getAudioTracks().length,
        });

        console.log(
          'Audio tracks:',
          stream.getAudioTracks().map(t => ({
            id: t.id,
            label: t.label,
            enabled: t.enabled,
            settings: t.getSettings(),
          }))
        );

        setLocalStream(stream);

        if (localVideoRef.current) {
          localVideoRef.current.srcObject = stream;
        }

        // ê¸°ì¡´ peerë“¤ì—ê²Œ ìƒˆ íŠ¸ë™ ì „ë‹¬ (ë§ˆì´í¬ ë³€ê²½ ì‹œ)
        if (peersRef.current.size > 0) {
          console.log(
            `ğŸ”„ Updating tracks for ${peersRef.current.size} existing peers`
          );
          peersRef.current.forEach((peer, targetUserId) => {
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            const peerConnection = (peer as any)._pc;

            if (peerConnection) {
              const videoTrack = stream.getVideoTracks()[0];
              const audioTrack = stream.getAudioTracks()[0];

              if (videoTrack) {
                const videoSender = peerConnection
                  .getSenders()
                  .find((s: RTCRtpSender) => s.track?.kind === 'video');
                if (videoSender) {
                  videoSender
                    .replaceTrack(videoTrack)
                    .then(() =>
                      console.log(`âœ… Video track replaced for ${targetUserId}`)
                    )
                    .catch((err: Error) =>
                      console.error(`âŒ Failed to replace video track:`, err)
                    );
                }
              }

              if (audioTrack) {
                const audioSender = peerConnection
                  .getSenders()
                  .find((s: RTCRtpSender) => s.track?.kind === 'audio');
                if (audioSender) {
                  audioSender
                    .replaceTrack(audioTrack)
                    .then(() =>
                      console.log(`âœ… Audio track replaced for ${targetUserId}`)
                    )
                    .catch((err: Error) =>
                      console.error(`âŒ Failed to replace audio track:`, err)
                    );
                }
              }
            }
          });
        }
      }

      // ìŠ¤íŠ¸ë¦¼ ì¤€ë¹„ ì™„ë£Œ ì•Œë¦¼ì€ VideoGridì—ì„œ ì²˜ë¦¬
    } catch (err) {
      console.error('âŒ Error accessing media devices:', err);
      setError('ì¹´ë©”ë¼ì™€ ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    } finally {
      setIsLoading(false);
    }
  }, []);

  // Peer ì—°ê²° ìƒì„±
  const createPeer = useCallback(
    (targetUserId: string, isInitiator: boolean): PeerInstance => {
      console.log(
        `ğŸ”— Creating peer for ${targetUserId}, initiator: ${isInitiator}`
      );

      const peer = new SimplePeer({
        initiator: isInitiator,
        trickle: true, // trueë¡œ ë³€ê²½í•˜ì—¬ ICE candidateë¥¼ ì¦‰ì‹œ ì „ì†¡
        stream: localStream || undefined,
        config: {
          iceServers: [
            { urls: 'stun:stun.l.google.com:19302' },
            {
              urls: ['turn:openrelay.metered.ca:80'],
              username: 'openrelayproject',
              credential: 'openrelayproject',
            },
          ],
          iceCandidatePoolSize: 10, // ICE candidate í’€ í¬ê¸° ì¦ê°€
        },
        // ì—°ê²° ì•ˆì •ì„±ì„ ìœ„í•œ ì¶”ê°€ ì„¤ì •
        objectMode: false,
        channelConfig: {
          ordered: false, // ìˆœì„œ ë³´ì¥ ë¹„í™œì„±í™”ë¡œ ì„±ëŠ¥ í–¥ìƒ
          maxRetransmits: 0, // ì¬ì „ì†¡ ë¹„í™œì„±í™”
        },
      });
      peer.on('iceStateChange', state => {
        console.log('ICE state:', state);
      });
      peer.on('signal', (signal: SignalData) => {
        console.log(`ğŸ“¡ Sending signal to ${targetUserId}:`, signal.type);
        if ('candidate' in signal && signal.candidate)
          console.log('ICE candidate:', signal.candidate);

        const payload: WebRTCSignalPayload = {
          roomId,
          userId,
          targetUserId,
          signal,
          type:
            signal.type === 'offer'
              ? 'offer'
              : signal.type === 'answer'
                ? 'answer'
                : 'ice_candidate',
        };
        socket?.emit('webrtc_signal', payload);
      });

      peer.on('stream', (stream: MediaStream) => {
        console.log(`ğŸ“¹ Received stream from ${targetUserId}`);
        const audioTrack = stream.getAudioTracks()[0];
        const videoTrack = stream.getVideoTracks()[0];

        console.log(`Stream tracks:`, {
          video: stream.getVideoTracks().length,
          audio: stream.getAudioTracks().length,
          audioEnabled: audioTrack?.enabled,
          videoEnabled: videoTrack?.enabled,
        });

        // ì´ˆê¸° íŠ¸ë™ ìƒíƒœ ì €ì¥
        setRemoteTrackStates(
          prev =>
            new Map(
              prev.set(targetUserId, {
                isAudioEnabled: audioTrack?.enabled ?? false,
                isVideoEnabled: videoTrack?.enabled ?? false,
              })
            )
        );

        // íŠ¸ë™ ìƒíƒœ ë³€ê²½ ë¦¬ìŠ¤ë„ˆ ì¶”ê°€
        stream.getTracks().forEach(track => {
          track.onended = () => {
            console.log(`ğŸ”‡ Track ended for ${targetUserId}:`, track.kind);
          };
          track.onmute = () => {
            console.log(`ğŸ”‡ Track muted for ${targetUserId}:`, track.kind);
          };
          track.onunmute = () => {
            console.log(`ğŸ”Š Track unmuted for ${targetUserId}:`, track.kind);
          };
        });

        setRemoteStreams(prev => new Map(prev.set(targetUserId, stream)));
      });

      peer.on('connect', () => {
        console.log(`âœ… Peer connected: ${targetUserId}`);
        setIsConnected(true);
      });

      peer.on('error', (err: Error) => {
        console.error(`âŒ Peer error (${targetUserId}):`, err);
        setError(`ì—°ê²° ì˜¤ë¥˜: ${err.message}`);
      });

      peer.on('close', () => {
        console.log(`ğŸ‘‹ Peer disconnected: ${targetUserId}`);
        setRemoteStreams(prev => {
          const newMap = new Map(prev);
          newMap.delete(targetUserId);
          return newMap;
        });
        setRemoteTrackStates(prev => {
          const newMap = new Map(prev);
          newMap.delete(targetUserId);
          return newMap;
        });
        peersRef.current.delete(targetUserId);
      });

      return peer;
    },
    [localStream, roomId, userId, socket]
  );

  // WebRTC ì‹œê·¸ë„ ì²˜ë¦¬
  const handleWebRTCSignal = useCallback(
    (data: WebRTCSignalPayload & { userId: string }) => {
      const senderId = data.userId; // ë³´ë‚¸ ì‚¬ëŒ
      const { signal, type } = data;

      console.log(`ğŸ“¥ Received ${type} from ${senderId}`);

      if (senderId === userId) return; // ìì‹ ì´ ë³´ë‚¸ ì‹ í˜¸ëŠ” ë¬´ì‹œ

      const existingPeer = peersRef.current.get(senderId);

      if (type === 'offer') {
        console.log(`ğŸ¤ Handling offer from ${senderId}`);
        // Offerë¥¼ ë°›ìœ¼ë©´ answerë¥¼ ë³´ë‚¼ Peer ìƒì„±
        if (existingPeer) {
          existingPeer.destroy();
        }
        const newPeer = createPeer(senderId, false);
        newPeer.signal(signal);
        peersRef.current.set(senderId, newPeer);
      } else if (type === 'answer' && existingPeer) {
        console.log(`âœ… Handling answer from ${senderId}`);
        existingPeer.signal(signal);
      } else if (type === 'ice_candidate' && existingPeer) {
        console.log(`ğŸ§Š Handling ICE candidate from ${senderId}`);
        try {
          existingPeer.signal(signal);
        } catch (err) {
          console.warn('Failed to add ICE candidate:', err);
        }
      }
    },
    [userId, createPeer]
  );

  // ì‚¬ìš©ì ì°¸ì—¬ ì²˜ë¦¬
  const handleUserJoined = useCallback(
    (userData: WebRTCUser) => {
      console.log(`ğŸ‘¤ User joined:`, userData);
      if (userData.id === userId) return;

      // ì´ë¯¸ ì—°ê²° ì‹œë„ ì¤‘ì´ë©´ ë¬´ì‹œ
      if (peersRef.current.has(userData.id)) {
        console.log(`âš ï¸ Already have peer for ${userData.id}`);
        return;
      }

      // ë¡œì»¬ ìŠ¤íŠ¸ë¦¼ì´ ì¤€ë¹„ëœ ê²½ìš°ì—ë§Œ ì—°ê²° ì‹œë„
      if (localStream) {
        // userId ë¹„êµë¡œ initiator ê²°ì • (ë¬¸ìì—´ ë¹„êµë¡œ ì¼ê´€ì„± ë³´ì¥)
        const shouldInitiate = userId < userData.id;
        console.log(
          `ğŸ”— ${shouldInitiate ? 'Initiating' : 'Waiting for'} connection to ${userData.id} (my ID: ${userId})`
        );

        if (shouldInitiate) {
          const peer = createPeer(userData.id, true);
          peersRef.current.set(userData.id, peer);
        }
      } else {
        console.log(`â³ Waiting for local stream to connect to ${userData.id}`);
      }
    },
    [userId, localStream, createPeer]
  );

  // ì‚¬ìš©ì ë‚˜ê°€ê¸° ì²˜ë¦¬
  const handleUserLeft = useCallback((leftUserId: string) => {
    const peer = peersRef.current.get(leftUserId);
    if (peer) {
      peer.destroy();
      peersRef.current.delete(leftUserId);
    }

    setRemoteStreams(prev => {
      const newMap = new Map(prev);
      newMap.delete(leftUserId);
      return newMap;
    });

    setRemoteTrackStates(prev => {
      const newMap = new Map(prev);
      newMap.delete(leftUserId);
      return newMap;
    });
  }, []);

  // ì›ê²© ìŠ¤íŠ¸ë¦¼ì˜ íŠ¸ë™ ìƒíƒœë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ (500msë§ˆë‹¤)
  useEffect(() => {
    const interval = setInterval(() => {
      if (remoteStreams.size > 0) {
        setRemoteTrackStates(prev => {
          const newMap = new Map(prev);
          let hasChanges = false;

          remoteStreams.forEach((stream, userId) => {
            const audioTrack = stream.getAudioTracks()[0];
            const videoTrack = stream.getVideoTracks()[0];
            const currentState = prev.get(userId);
            const newState = {
              isAudioEnabled: audioTrack?.enabled ?? false,
              isVideoEnabled: videoTrack?.enabled ?? false,
            };

            // ìƒíƒœê°€ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ ì—…ë°ì´íŠ¸
            if (
              !currentState ||
              currentState.isAudioEnabled !== newState.isAudioEnabled ||
              currentState.isVideoEnabled !== newState.isVideoEnabled
            ) {
              newMap.set(userId, newState);
              hasChanges = true;
              console.log(`ğŸ”„ Track state changed for ${userId}:`, newState);
            }
          });

          return hasChanges ? newMap : prev;
        });
      }
    }, 500);

    return () => clearInterval(interval);
  }, [remoteStreams]);

  // Socket ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡
  useEffect(() => {
    if (!socket) return;

    // stream_ready ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ (ë°±ì—”ë“œì—ì„œ userIdë¡œ ë³´ëƒ„ â†’ idë¡œ ë³€í™˜)
    const handleStreamReady = (data: {
      userId: string;
      userName: string;
      socketId: string;
    }) => {
      console.log('ğŸ“¹ Stream ready event:', data);
      handleUserJoined({
        id: data.userId, // âœ… userId â†’ id ë³€í™˜
        name: data.userName,
        isMentor: false,
      });
    };

    // user_joined ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ (ë°±ì—”ë“œì—ì„œ userIdë¡œ ë³´ëƒ„ â†’ idë¡œ ë³€í™˜)
    const handleUserJoinedEvent = (data: {
      userId: string;
      userName: string;
      userImage?: string;
      isMentor?: boolean;
      socketId: string;
    }) => {
      console.log('ğŸ‘¤ User joined event:', data);
      handleUserJoined({
        id: data.userId, // âœ… userId â†’ id ë³€í™˜
        name: data.userName,
        image: data.userImage,
        isMentor: data.isMentor ?? false,
      });
    };

    socket.on('webrtc_signal', handleWebRTCSignal);
    socket.on('user_joined', handleUserJoinedEvent);
    socket.on('user_left', handleUserLeft);
    socket.on('stream_ready', handleStreamReady);

    return () => {
      socket.off('webrtc_signal', handleWebRTCSignal);
      socket.off('user_joined', handleUserJoinedEvent);
      socket.off('user_left', handleUserLeft);
      socket.off('stream_ready', handleStreamReady);
    };
  }, [socket, handleWebRTCSignal, handleUserJoined, handleUserLeft]);

  // ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    const currentPeers = peersRef.current;
    const currentStream = localStream;

    return () => {
      currentPeers.forEach(peer => peer.destroy());
      currentPeers.clear();
      if (currentStream) currentStream.getTracks().forEach(t => t.stop());
    };
  }, [localStream]);

  // ë¹„ë””ì˜¤/ì˜¤ë””ì˜¤ í† ê¸€
  const toggleVideo = useCallback(() => {
    if (!localStream) return;
    const videoTrack = localStream.getVideoTracks()[0];
    if (videoTrack) videoTrack.enabled = !videoTrack.enabled;
  }, [localStream]);

  const toggleAudio = useCallback(() => {
    if (!localStream) return;
    const audioTrack = localStream.getAudioTracks()[0];
    if (audioTrack) audioTrack.enabled = !audioTrack.enabled;
  }, [localStream]);

  // í™”ë©´ ê³µìœ  ì¤‘ì§€
  const stopScreenShare = useCallback(async () => {
    try {
      if (!originalStream) {
        console.warn('âš ï¸ No original stream to restore');
        return;
      }

      // í™”ë©´ê³µìœ  ìƒíƒœë¥¼ ë¨¼ì € falseë¡œ ì„¤ì •
      setIsScreenSharing(false);

      // í˜„ì¬ í™”ë©´ ê³µìœ  ìŠ¤íŠ¸ë¦¼ ì •ì§€
      if (localStream) {
        console.log('ğŸ›‘ Stopping screen share tracks');
        localStream.getTracks().forEach(track => {
          track.stop();
          console.log(`Stopped track: ${track.kind}`);
        });
      }

      // ì›ë˜ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³µì›
      console.log('ğŸ”„ Restoring original camera stream');
      setLocalStream(originalStream);

      if (localVideoRef.current) {
        localVideoRef.current.srcObject = originalStream;
      }

      // ëª¨ë“  Peerì— ì›ë˜ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë³µì› (ì•ˆì •ì ì¸ ë°©ì‹)
      const restoreTracksForPeer = async (peer: any, userId: string) => {
        const videoTrack = originalStream.getVideoTracks()[0];
        const audioTrack = originalStream.getAudioTracks()[0];

        // eslint-disable-next-line @typescript-eslint/no-explicit-any
        const peerConnection = (peer as any)._pc;

        if (!peerConnection) {
          console.warn(`âš ï¸ No peer connection for ${userId}`);
          return;
        }

        // ì—°ê²° ìƒíƒœ í™•ì¸ (ë” ì—„ê²©í•œ ê²€ì‚¬)
        if (
          peerConnection.connectionState === 'closed' ||
          peerConnection.connectionState === 'failed' ||
          peerConnection.connectionState === 'disconnected'
        ) {
          console.warn(
            `âš ï¸ Peer connection is ${peerConnection.connectionState} for ${userId}, skipping track restoration`
          );
          return;
        }

        // ì—°ê²°ì´ ì•„ì§ ì„¤ì • ì¤‘ì¸ ê²½ìš° ì ì‹œ ëŒ€ê¸°
        if (peerConnection.connectionState === 'connecting') {
          console.log(
            `â³ Peer connection is connecting for ${userId}, waiting...`
          );
          await new Promise(resolve => setTimeout(resolve, 200));

          // ë‹¤ì‹œ í™•ì¸
          const stateAfterWait: RTCPeerConnectionState =
            peerConnection.connectionState;
          if (stateAfterWait !== 'connected') {
            console.warn(
              `âš ï¸ Peer connection still not connected for ${userId}, skipping`
            );
            return;
          }
        }

        console.log(`ğŸ”„ Restoring tracks for peer: ${userId}`);

        try {
          if (videoTrack) {
            const videoSender = peerConnection
              .getSenders()
              .find((s: RTCRtpSender) => s.track?.kind === 'video');
            if (videoSender) {
              await videoSender.replaceTrack(videoTrack);
              console.log(`âœ… Video track restored for ${userId}`);
            }
          }

          if (audioTrack) {
            const audioSender = peerConnection
              .getSenders()
              .find((s: RTCRtpSender) => s.track?.kind === 'audio');
            if (audioSender) {
              await audioSender.replaceTrack(audioTrack);
              console.log(`âœ… Audio track restored for ${userId}`);
            }
          }

          console.log(
            `ğŸ“Š Connection state after track restoration: ${peerConnection.connectionState}`
          );
        } catch (error) {
          console.error(`âŒ Failed to restore tracks for ${userId}:`, error);
        }
      };

      // ê° peerì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ íŠ¸ë™ ë³µì›
      const restoreTracksSequentially = async () => {
        for (const [userId, peer] of peersRef.current.entries()) {
          await restoreTracksForPeer(peer, userId);
          // ê° peer ì‚¬ì´ì— ì•½ê°„ì˜ ì§€ì—°
          await new Promise(resolve => setTimeout(resolve, 50));
        }
      };

      // íŠ¸ë™ ë³µì› ì‹¤í–‰ (ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰)
      try {
        await restoreTracksSequentially();

        // í™”ë©´ê³µìœ  ì¤‘ì§€ í›„ ì¬í˜‘ìƒ íŠ¸ë¦¬ê±°
        for (const [targetUserId, peer] of peersRef.current.entries()) {
          try {
            console.log(
              `ğŸ“¡ Triggering renegotiation after restore with ${targetUserId}`
            );

            // SimplePeerì˜ renegotiate ë©”ì„œë“œ ì‚¬ìš©
            if (typeof (peer as any).renegotiate === 'function') {
              (peer as any).renegotiate();
              console.log(
                `âœ… Restore renegotiation triggered for ${targetUserId}`
              );
            } else {
              // fallback: ì§ì ‘ offer ìƒì„±
              const pc: RTCPeerConnection | undefined = (peer as any)?._pc;
              if (pc && pc.connectionState === 'connected') {
                const offer = await pc.createOffer();
                await pc.setLocalDescription(offer);

                const payload: WebRTCSignalPayload = {
                  roomId,
                  userId,
                  targetUserId,
                  signal: offer as unknown as SignalData,
                  type: 'offer',
                };

                socket?.emit('webrtc_signal', payload);
                console.log(
                  `âœ… Fallback restore renegotiation sent for ${targetUserId}`
                );
              }
            }
          } catch (err) {
            console.error(
              `âŒ Restore renegotiation failed for ${targetUserId}:`,
              err
            );
          }
        }
      } catch (error) {
        console.error('âŒ Error during track restoration:', error);
      }

      // ì†Œì¼“ìœ¼ë¡œ í™”ë©´ ê³µìœ  ì¤‘ì§€ ìƒíƒœ ì „ì†¡
      socket?.emit('screen_share_stopped', { roomId, userId });
      console.log('âœ… Screen share stopped successfully');

      setOriginalStream(null);
    } catch (err) {
      console.error('âŒ Error stopping screen share:', err);
      setError('í™”ë©´ ê³µìœ ë¥¼ ì¤‘ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }
  }, [originalStream, localStream, roomId, userId, socket]);

  // í™”ë©´ ê³µìœ  ì‹œì‘
  const startScreenShare = useCallback(
    async (_source: 'screen' | 'window' | 'tab' = 'screen') => {
      try {
        setIsLoading(true);

        // í˜„ì¬ ìŠ¤íŠ¸ë¦¼ ì €ì¥ (ë³µì›ìš©)
        if (localStream && !isScreenSharing) {
          setOriginalStream(localStream);
        }

        // ë¸Œë¼ìš°ì €ê°€ ìì²´ ì„ íƒ UIë¥¼ ì œê³µí•˜ë¯€ë¡œ displaySurfaceëŠ” ë¬´ì‹œ
        const constraints: DisplayMediaConstraints = {
          video: {
            width: { ideal: 1920 },
            height: { ideal: 1080 },
          },
          audio: true,
        };

        const screenStream = await navigator.mediaDevices.getDisplayMedia(
          constraints as MediaStreamConstraints
        );

        console.log('ğŸ“º Screen share stream created:', {
          videoTracks: screenStream.getVideoTracks().length,
          audioTracks: screenStream.getAudioTracks().length,
          videoTrack: screenStream.getVideoTracks()[0]?.getSettings(),
        });

        setLocalStream(screenStream);
        setIsScreenSharing(true);

        if (localVideoRef.current) {
          localVideoRef.current.srcObject = screenStream;
        }

        // ëª¨ë“  Peerì— ìƒˆ ìŠ¤íŠ¸ë¦¼ ì „ì†¡ (ë” ì•ˆì •ì ì¸ ë°©ì‹)
        const replaceTracksForPeer = async (
          peer: any,
          targetUserId: string
        ) => {
          const videoTrack = screenStream.getVideoTracks()[0];
          const audioTrack = screenStream.getAudioTracks()[0];

          // eslint-disable-next-line @typescript-eslint/no-explicit-any
          const peerConnection = (peer as any)._pc;

          if (!peerConnection) {
            console.warn(`âš ï¸ No peer connection for ${targetUserId}`);
            return;
          }

          // ì—°ê²° ìƒíƒœ í™•ì¸ (ë” ì—„ê²©í•œ ê²€ì‚¬)
          if (
            peerConnection.connectionState === 'closed' ||
            peerConnection.connectionState === 'failed' ||
            peerConnection.connectionState === 'disconnected'
          ) {
            console.warn(
              `âš ï¸ Peer connection is ${peerConnection.connectionState} for ${targetUserId}, skipping track replacement`
            );
            return;
          }

          // ì—°ê²°ì´ ì•„ì§ ì„¤ì • ì¤‘ì¸ ê²½ìš° ì ì‹œ ëŒ€ê¸°
          if (peerConnection.connectionState === 'connecting') {
            console.log(
              `â³ Peer connection is connecting for ${targetUserId}, waiting...`
            );
            await new Promise(resolve => setTimeout(resolve, 300));

            // ë‹¤ì‹œ í™•ì¸
            if (
              peerConnection.connectionState === 'connecting' ||
              peerConnection.connectionState === 'disconnected'
            ) {
              console.warn(
                `âš ï¸ Peer connection still not ready for ${targetUserId}, skipping`
              );
              return;
            }
          }

          console.log(
            `ğŸ”„ Replacing tracks for screen share to ${targetUserId}`
          );

          try {
            // ë¹„ë””ì˜¤ íŠ¸ë™ êµì²´
            if (videoTrack) {
              const videoSender = peerConnection
                .getSenders()
                .find((s: RTCRtpSender) => s.track?.kind === 'video');
              if (videoSender) {
                await videoSender.replaceTrack(videoTrack);
                console.log(
                  `âœ… Video track replaced for screen share to ${targetUserId}`
                );
              } else {
                console.warn(`âš ï¸ No video sender found for ${targetUserId}`);
              }
            }

            // ì˜¤ë””ì˜¤ íŠ¸ë™ êµì²´ (í™”ë©´ê³µìœ ì— ì˜¤ë””ì˜¤ê°€ í¬í•¨ëœ ê²½ìš°)
            if (audioTrack) {
              const audioSender = peerConnection
                .getSenders()
                .find((s: RTCRtpSender) => s.track?.kind === 'audio');
              if (audioSender) {
                await audioSender.replaceTrack(audioTrack);
                console.log(
                  `âœ… Audio track replaced for screen share to ${targetUserId}`
                );
              }
            }

            console.log(
              `ğŸ“Š Connection state after track replacement: ${peerConnection.connectionState}`
            );
          } catch (error) {
            console.error(
              `âŒ Failed to replace tracks for ${targetUserId}:`,
              error
            );
          }
        };

        // ê° peerì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ íŠ¸ë™ êµì²´
        const replaceTracksSequentially = async () => {
          for (const [targetUserId, peer] of peersRef.current.entries()) {
            await replaceTracksForPeer(peer, targetUserId);
            // ê° peer ì‚¬ì´ì— ì•½ê°„ì˜ ì§€ì—°
            await new Promise(resolve => setTimeout(resolve, 50));
          }
        };

        // íŠ¸ë™ êµì²´ ì‹¤í–‰
        await replaceTracksSequentially();

        // í™”ë©´ê³µìœ  í›„ ì¬í˜‘ìƒ íŠ¸ë¦¬ê±° (ë” ì•ˆì „í•œ ë°©ì‹)
        for (const [targetUserId, peer] of peersRef.current.entries()) {
          try {
            console.log(`ğŸ“¡ Triggering renegotiation with ${targetUserId}`);

            // SimplePeerì˜ renegotiate ë©”ì„œë“œ ì‚¬ìš©
            if (typeof (peer as any).renegotiate === 'function') {
              (peer as any).renegotiate();
              console.log(`âœ… Renegotiation triggered for ${targetUserId}`);
            } else {
              // fallback: ì§ì ‘ offer ìƒì„±
              const pc: RTCPeerConnection | undefined = (peer as any)?._pc;
              if (pc && pc.connectionState === 'connected') {
                const offer = await pc.createOffer();
                await pc.setLocalDescription(offer);

                const payload: WebRTCSignalPayload = {
                  roomId,
                  userId,
                  targetUserId,
                  signal: offer as unknown as SignalData,
                  type: 'offer',
                };

                socket?.emit('webrtc_signal', payload);
                console.log(
                  `âœ… Fallback renegotiation sent for ${targetUserId}`
                );
              }
            }
          } catch (err) {
            console.error(`âŒ Renegotiation failed for ${targetUserId}:`, err);
          }
        }

        // í™”ë©´ ê³µìœ  ì¢…ë£Œ ì´ë²¤íŠ¸ ì²˜ë¦¬ (ì‚¬ìš©ìê°€ ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ ì¤‘ì§€)
        screenStream.getVideoTracks()[0].onended = () => {
          stopScreenShare();
        };

        // ì†Œì¼“ìœ¼ë¡œ í™”ë©´ ê³µìœ  ìƒíƒœ ì „ì†¡
        socket?.emit('screen_share_started', { roomId, userId });
      } catch (err) {
        console.error('Error starting screen share:', err);
        setError('í™”ë©´ ê³µìœ ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');

        // í™”ë©´ ê³µìœ  ì·¨ì†Œ ì‹œ ì›ë˜ ìŠ¤íŠ¸ë¦¼ ë³µì›
        if (isScreenSharing && originalStream) {
          setLocalStream(originalStream);
          setIsScreenSharing(false);
          setOriginalStream(null);
        }
      } finally {
        setIsLoading(false);
      }
    },
    [
      localStream,
      isScreenSharing,
      roomId,
      userId,
      socket,
      stopScreenShare,
      originalStream,
    ]
  );

  return {
    localStream,
    remoteStreams,
    remoteTrackStates,
    isConnected,
    isLoading,
    error,
    isScreenSharing,
    localVideoRef,
    initializeLocalStream,
    toggleVideo,
    toggleAudio,
    startScreenShare,
    stopScreenShare,
  };
};
